{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd2a921",
   "metadata": {},
   "source": [
    "# Data Cleaning with Pandas and Visualizations\n",
    "This notebook demonstrates five common data cleaning techniques using pandas, with generated data and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd446f6e",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- `import pandas as pd`: Loads the pandas library, which is essential for data manipulation and analysis in Python.\n",
    "- `import numpy as np`: Loads numpy, a library for efficient numerical operations and random data generation.\n",
    "- `import matplotlib.pyplot as plt`: Loads matplotlib's plotting module, used for creating visualizations to better understand and communicate data cleaning steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d075f",
   "metadata": {},
   "source": [
    "## 1. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a65d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with missing values\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randn(100),\n",
    "    'B': np.random.choice([np.nan, 1, 2, 3], size=100)\n",
    "})\n",
    "\n",
    "# Visualize missing values\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Missing Values Before Cleaning\")\n",
    "plt.bar(['A', 'B'], [df['A'].isna().sum(), df['B'].isna().sum()])\n",
    "plt.show()\n",
    "\n",
    "# Fill missing values\n",
    "df['B'] = df['B'].fillna(df['B'].mean())\n",
    "\n",
    "# Visualize after cleaning\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Missing Values After Cleaning\")\n",
    "plt.bar(['A', 'B'], [df['A'].isna().sum(), df['B'].isna().sum()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469dc795",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- Generates a DataFrame with random values and introduces missing values (`np.nan`) in column 'B' to simulate real-world data issues.\n",
    "- Uses `plt.bar` to visualize the number of missing values in each column before cleaning, helping identify which columns need attention.\n",
    "- Fills missing values in column 'B' with the mean of the non-missing values using `fillna(df['B'].mean())`, a common imputation technique.\n",
    "- Visualizes the columns again after cleaning to confirm that missing values have been handled, ensuring the dataset is ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca449f47",
   "metadata": {},
   "source": [
    "## 2. Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with duplicates\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.randint(0, 10, 100),\n",
    "    'B': np.random.randint(0, 10, 100)\n",
    "})\n",
    "df = pd.concat([df, df.iloc[:10]], ignore_index=True)  # Add duplicates\n",
    "\n",
    "# Visualize duplicates\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Number of Rows Before Removing Duplicates\")\n",
    "plt.bar(['Rows'], [len(df)])\n",
    "plt.show()\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df.drop_duplicates()\n",
    "\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Number of Rows After Removing Duplicates\")\n",
    "plt.bar(['Rows'], [len(df_clean)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe57af",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- Creates a DataFrame with random integer values and deliberately adds duplicate rows to mimic common data entry errors.\n",
    "- Visualizes the total number of rows before cleaning to show the effect of duplicates on dataset size.\n",
    "- Uses `drop_duplicates()` to remove repeated rows, ensuring each record is unique and improving data quality.\n",
    "- Visualizes the row count after cleaning to demonstrate the reduction in duplicates and confirm the cleaning step was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20b565",
   "metadata": {},
   "source": [
    "## 3. Converting Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with wrong types\n",
    "df = pd.DataFrame({\n",
    "    'date': ['2025-08-26', '2025-08-27', '2025-08-28', 'not_a_date'],\n",
    "    'value': ['1', '2', 'three', '4']\n",
    "})\n",
    "\n",
    "# Before conversion\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Data Types Before Cleaning\")\n",
    "plt.bar(df.columns, [df[col].dtype == 'object' for col in df.columns])\n",
    "plt.show()\n",
    "\n",
    "# Convert types\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df['value'] = pd.to_numeric(df['value'], errors='coerce')\n",
    "\n",
    "# After conversion\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Data Types After Cleaning\")\n",
    "plt.bar(df.columns, [df[col].dtype == 'object' for col in df.columns])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f694277",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- Generates a DataFrame with columns containing string representations of dates and numbers, including some invalid entries to simulate messy data.\n",
    "- Visualizes the data types before cleaning to highlight columns that need conversion for proper analysis.\n",
    "- Converts the 'date' column to datetime format and the 'value' column to numeric, using error coercion to handle invalid entries gracefully.\n",
    "- Visualizes the data types after cleaning to confirm successful conversion, which is essential for accurate computations and time-based analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e380c0",
   "metadata": {},
   "source": [
    "## 4. Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe100a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data with outliers\n",
    "data = np.random.normal(50, 10, 100)\n",
    "data[::10] = 200  # Add outliers\n",
    "df = pd.DataFrame({'value': data})\n",
    "\n",
    "# Visualize before cleaning\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Boxplot Before Removing Outliers\")\n",
    "plt.boxplot(df['value'])\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers\n",
    "q_low = df['value'].quantile(0.01)\n",
    "q_high = df['value'].quantile(0.99)\n",
    "df_clean = df[(df['value'] > q_low) & (df['value'] < q_high)]\n",
    "\n",
    "# Visualize after cleaning\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"Boxplot After Removing Outliers\")\n",
    "plt.boxplot(df_clean['value'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e14060c",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- Generates a dataset with normally distributed values and injects extreme outliers to simulate real-world measurement errors or anomalies.\n",
    "- Visualizes the data distribution with a boxplot before cleaning, making it easy to spot outliers.\n",
    "- Removes outliers by filtering values outside the 1st and 99th percentiles, a robust method to retain most data while excluding extreme values.\n",
    "- Visualizes the cleaned data with another boxplot to confirm that outliers have been removed, resulting in a more reliable dataset for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79e352",
   "metadata": {},
   "source": [
    "## 5. Standardizing Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee976ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate messy text data\n",
    "df = pd.DataFrame({\n",
    "    'city': ['New York', 'new york', 'NEW YORK', 'Los Angeles', 'los angeles', 'LOS ANGELES']\n",
    "})\n",
    "\n",
    "# Before cleaning\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"City Value Counts Before Cleaning\")\n",
    "df['city'].value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "\n",
    "# Standardize text\n",
    "df['city'] = df['city'].str.lower().str.strip().str.title()\n",
    "\n",
    "# After cleaning\n",
    "plt.figure(figsize=(6,2))\n",
    "plt.title(\"City Value Counts After Cleaning\")\n",
    "df['city'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41dfb27",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "- Creates a DataFrame with city names in various cases and formats to mimic inconsistent data entry.\n",
    "- Visualizes the frequency of each city name before cleaning, showing how inconsistent formatting can fragment your data.\n",
    "- Standardizes the city names by converting them to lowercase, stripping whitespace, and applying title case, ensuring consistency for grouping and analysis.\n",
    "- Visualizes the value counts after cleaning to demonstrate the effectiveness of standardization, making the data ready for reliable aggregation and reporting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
